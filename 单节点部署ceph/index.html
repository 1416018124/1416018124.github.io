
<!DOCTYPE html>
<html lang="zh-cn">
    
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="generator" content="Hexo">
    <title>单节点部署ceph - Hexo</title>
    <meta name="author" content="Jiang Feng">
    
        <meta name="keywords" content="javascript,hexo">
    
    
    
    <script type="application/ld+json">{"@context":"http://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Jiang Feng","sameAs":["https://github.com/1416018124"]},"articleBody":"\n\n1.机器规划\n\n\nhostname\nip\n配置\nos\n\n\n\nceph\n192.168.3.27\n8c-32g\nubuntut 22.04.5lts\n\n\n2.软件部署2.1前置依赖123456789apt-get install apt-transport-https ca-certificates curl software-properties-common -ycurl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpgecho &quot;deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu jammy stable&quot; | sudo tee /etc/apt/sources.list.d/docker.list &gt; /dev/null apt-get update apt-get install docker-ce docker-ce-cli containerd.io -y apt-get install ntp lvm2 -y tzselect cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime\n\n\n\n2.2安装cephadm12wget -q -O- ‘https://download.ceph.com/keys/release.asc’ | sudo apt-key add -apt-get install cephadm\n\n\n\n1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192cephadm bootstrap --mon-ip 192.168.142.103Creating directory /etc/ceph for ceph.confVerifying podman|docker is present...Verifying lvm2 is present...Verifying time synchronization is in place...Unit ntp.service is enabled and runningRepeating the final host check...docker (/usr/bin/docker) is presentsystemctl is presentlvcreate is presentUnit ntp.service is enabled and runningHost looks OKCluster fsid: 0a772fca-c53c-11ef-ae86-ed4a98cf590aVerifying IP 192.168.3.27 port 3300 ...Verifying IP 192.168.3.27 port 6789 ...Mon IP `192.168.3.27` is in CIDR network `192.168.3.0/24`Mon IP `192.168.3.27` is in CIDR network `192.168.3.0/24`Mon IP `192.168.3.27` is in CIDR network `192.168.3.1/32`Mon IP `192.168.3.27` is in CIDR network `192.168.3.1/32`Internal network (--cluster-network) has not been provided, OSD replication will default to the public_networkPulling container image quay.io/ceph/ceph:v17...Ceph version: ceph version 17.2.8 (f817ceb7f187defb1d021d6328fa833eb8e943b3) quincy (stable)Extracting ceph user uid/gid from container image...Creating initial keys...Creating initial monmap...Creating mon...Waiting for mon to start...Waiting for mon...mon is availableAssimilating anything we can from ceph.conf...Generating new minimal ceph.conf...Restarting the monitor...Setting mon public_network to 192.168.3.1/32,192.168.3.0/24Wrote config to /etc/ceph/ceph.confWrote keyring to /etc/ceph/ceph.client.admin.keyringCreating mgr...Verifying port 9283 ...Waiting for mgr to start...Waiting for mgr...mgr not available, waiting (1/15)...mgr not available, waiting (2/15)...mgr not available, waiting (3/15)...mgr is availableEnabling cephadm module...Waiting for the mgr to restart...Waiting for mgr epoch 5...mgr epoch 5 is availableSetting orchestrator backend to cephadm...Generating ssh key...Wrote public SSH key to /etc/ceph/ceph.pubAdding key to root@localhost authorized_keys...Adding host ceph...Deploying mon service with default placement...Deploying mgr service with default placement...Deploying crash service with default placement...Deploying prometheus service with default placement...Deploying grafana service with default placement...Deploying node-exporter service with default placement...Deploying alertmanager service with default placement...Enabling the dashboard module...Waiting for the mgr to restart...Waiting for mgr epoch 9...mgr epoch 9 is availableGenerating a dashboard self-signed certificate...Creating initial admin user...Fetching dashboard port number...Ceph Dashboard is now available at:\t     URL: https://ceph:8443/\t    User: admin\tPassword: lvoxog77g8Enabling client.admin keyring and conf on hosts with &quot;admin&quot; labelSaving cluster configuration to /var/lib/ceph/0a772fca-c53c-11ef-ae86-ed4a98cf590a/config directoryEnabling autotune for osd_memory_targetYou can access the Ceph CLI as following in case of multi-cluster or non-default config:\tsudo /usr/sbin/cephadm shell --fsid 0a772fca-c53c-11ef-ae86-ed4a98cf590a -c /etc/ceph/ceph.conf -k /etc/ceph/ceph.client.admin.keyringOr, if you are only running a single cluster on this host:\tsudo /usr/sbin/cephadm shellPlease consider enabling telemetry to help improve Ceph:\tceph telemetry onFor more information see:\thttps://docs.ceph.com/docs/master/mgr/telemetry/Bootstrap complete.\n\n此时根据上面的url可以登录到dashboard上.\n安装ceph-common1234567891011121314151617cephadm add-repo --release pacificceph status  cluster:    id:     0a772fca-c53c-11ef-ae86-ed4a98cf590a    health: HEALTH_WARN            OSD count 0 &lt; osd_pool_default_size 3  services:    mon: 1 daemons, quorum ceph (age 16m)    mgr: ceph.cehgev(active, since 14m)    osd: 0 osds: 0 up, 0 in  data:    pools:   0 pools, 0 pgs    objects: 0 objects, 0 B    usage:   0 B used, 0 B / 0 B avail    pgs:\n\n\n\n3.添加存储1ceph orch apply osd --all-available-devices\n\n\n\n4.创建pool1234567891011#修改crush map#原因： 不然pool的创建会出问题，集群状态一直是不健康的，参考：Setting up a single node Ceph storage cluster#步骤：ceph status # Shows the status of the clusterceph osd crush rule dump # Shows you the current crush mapsceph osd getcrushmap -o comp_crush_map.cm # Get crush mapcrushtool -d comp_crush_map.cm -o crush_map.cm # Decompile mapvim crush_map.cm # Make and changes you need (host -&gt; osd)step chooseleaf firstn 0 type host 改为 step chooseleaf firstn 0 type osd,参考 如何在单节点 Ceph 中配置多数据副本crushtool -c crush_map.cm -o new_crush_map.cm # Compile mapceph osd setcrushmap -i new_crush_map.cm # Load the new map\n\n\n\n5.配置一个s3存储123456789101112# ceph orch apply rgw myrgw --placement=&quot;count:1&quot;# ceph orch lsNAME                       PORTS        RUNNING  REFRESHED  AGE  PLACEMENTalertmanager               ?:9093,9094      1/1  3m ago     38m  count:1crash                                       1/1  3m ago     38m  *grafana                    ?:3000           1/1  3m ago     38m  count:1mgr                                         1/2  3m ago     38m  count:2mon                                         1/5  3m ago     38m  count:5node-exporter              ?:9100           1/1  3m ago     38m  *osd.all-available-devices                     1  3m ago     19m  *prometheus                 ?:9095           1/1  3m ago     38m  count:1rgw.myrgw                  ?:80             1/1  3m ago     3m   count:1\n\n5.1生成s3访问凭证使用 radosgw-admin 命令来创建用户并生成 S3 访问所需的凭证：\n1radosgw-admin user create --uid=&quot;s3user&quot; --display-name=&quot;S3 User&quot;\n\n\n\n\n\n6.k8s上集成ceph123456#安装 Ceph-CSI 插件helm repo add ceph-csi https://ceph.github.io/csi-chartshelm repo updatekubectl create namespace ceph-cshelm install ceph-csi-cephfs ceph-csi/ceph-csi-cephfs --namespace ceph-csihelm install ceph-csi-rbd ceph-csi/ceph-csi-rbd --namespace ceph-csi\n\n6.1创建 Ceph 存储类你需要创建存储类（Storage Class）以便 Kubernetes 可以使用 Ceph 存储。\n对于 CephFS 存储类：\n123456789101112131415161718192021apiVersion: storage.k8s.io/v1kind: StorageClassmetadata:  name: cephfs-scprovisioner: cephfs.csi.ceph.comparameters:  # Ceph 集群的监视器地址  monitors: &lt;ceph_monitor_ips&gt;  # Ceph 集群的池名称  pool: &lt;cephfs_pool_name&gt;  # Ceph 集群的 CephFS 名称  clusterID: &lt;ceph_cluster_id&gt;  # Ceph 用户名称  csi.storage.k8s.io/provisioner-secret-name: csi-cephfs-secret  csi.storage.k8s.io/provisioner-secret-namespace: ceph-csi  csi.storage.k8s.io/node-stage-secret-name: csi-cephfs-secret  csi.storage.k8s.io/node-stage-secret-namespace: ceph-csi  # CephFS 根目录  rootPath: /reclaimPolicy: DeletevolumeBindingMode: Immediate\n\n\n\n对于 RBD 存储类：\n123456789101112131415161718192021apiVersion: storage.k8s.io/v1kind: StorageClassmetadata:  name: rbd-scprovisioner: rbd.csi.ceph.comparameters:  # Ceph 集群的监视器地址  monitors: &lt;ceph_monitor_ips&gt;  # Ceph 集群的池名称  pool: &lt;rbd_pool_name&gt;  # Ceph 用户名称  csi.storage.k8s.io/provisioner-secret-name: csi-rbd-secret  csi.storage.k8s.io/provisioner-secret-namespace: ceph-csi  csi.storage.k8s.io/node-stage-secret-name: csi-rbd-secret  csi.storage.k8s.io/node-stage-secret-namespace: ceph-csi  # RBD 映像格式  imageFormat: &quot;2&quot;  # RBD 映像特性  imageFeatures: &quot;layering&quot;reclaimPolicy: DeletevolumeBindingMode: Immediate\n\n将上述 YAML 文件保存为 cephfs-sc.yaml 或 rbd-sc.yaml，并使用以下命令创建存储类：\n12kubectl create -f cephfs-sc.yamlkubectl create -f rbd-sc.yaml\n","dateCreated":"2024-12-18T23:07:17+08:00","dateModified":"2025-03-12T22:31:24+08:00","datePublished":"2024-12-18T23:07:17+08:00","description":"","headline":"单节点部署ceph","image":["image-1.png","image-2.png"],"mainEntityOfPage":{"@type":"WebPage","@id":"https://1416018124.github.io/%E5%8D%95%E8%8A%82%E7%82%B9%E9%83%A8%E7%BD%B2ceph/"},"publisher":{"@type":"Organization","name":"Jiang Feng","sameAs":["https://github.com/1416018124"]},"url":"https://1416018124.github.io/%E5%8D%95%E8%8A%82%E7%82%B9%E9%83%A8%E7%BD%B2ceph/","keywords":"k8s, 运维","thumbnailUrl":"image-1.png"}</script>
    <meta name="description" content="1.机器规划   hostname ip 配置 os    ceph 192.168.3.27 8c-32g ubuntut 22.04.5lts   2.软件部署2.1前置依赖123456789apt-get install apt-transport-https ca-certificates curl software-properties-common -ycurl -fsSL htt">
<meta property="og:type" content="blog">
<meta property="og:title" content="单节点部署ceph">
<meta property="og:url" content="https://1416018124.github.io/%E5%8D%95%E8%8A%82%E7%82%B9%E9%83%A8%E7%BD%B2ceph/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="1.机器规划   hostname ip 配置 os    ceph 192.168.3.27 8c-32g ubuntut 22.04.5lts   2.软件部署2.1前置依赖123456789apt-get install apt-transport-https ca-certificates curl software-properties-common -ycurl -fsSL htt">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2024-12-18T15:07:17.000Z">
<meta property="article:modified_time" content="2025-03-12T14:31:24.491Z">
<meta property="article:author" content="Jiang Feng">
<meta property="article:tag" content="k8s">
<meta property="article:tag" content="运维">
<meta name="twitter:card" content="summary">
    
    
        
    
    
    
        <meta property="og:image" content="https://1416018124.github.io/%E5%8D%95%E8%8A%82%E7%82%B9%E9%83%A8%E7%BD%B2ceph/image-1.png"/>
        <meta class="swiftype" name="image" data-type="enum" content="https://1416018124.github.io/%E5%8D%95%E8%8A%82%E7%82%B9%E9%83%A8%E7%BD%B2ceph/image-1.png"/>
    
    
        <meta property="og:image" content="https://1416018124.github.io/%E5%8D%95%E8%8A%82%E7%82%B9%E9%83%A8%E7%BD%B2ceph/image-2.png"/>
        <meta class="swiftype" name="image" data-type="enum" content="https://1416018124.github.io/%E5%8D%95%E8%8A%82%E7%82%B9%E9%83%A8%E7%BD%B2ceph/image-2.png"/>
    
    
        
            <meta property="og:image" content="https://1416018124.github.io/%E5%8D%95%E8%8A%82%E7%82%B9%E9%83%A8%E7%BD%B2ceph/image-3.jpg"/>
            <meta class="swiftype" name="image" data-type="enum" content="https://1416018124.github.io/%E5%8D%95%E8%8A%82%E7%82%B9%E9%83%A8%E7%BD%B2ceph/image-3.jpg"/>
        
            <meta property="og:image" content="https://1416018124.github.io/%E5%8D%95%E8%8A%82%E7%82%B9%E9%83%A8%E7%BD%B2ceph/image-4.png"/>
            <meta class="swiftype" name="image" data-type="enum" content="https://1416018124.github.io/%E5%8D%95%E8%8A%82%E7%82%B9%E9%83%A8%E7%BD%B2ceph/image-4.png"/>
        
            <meta property="og:image" content="http://i.imgur.com/o9r19kD.jpg"/>
            <meta class="swiftype" name="image" data-type="enum" content="http://i.imgur.com/o9r19kD.jpg"/>
        
            <meta property="og:image" content="https://example.com/orignal.jpg"/>
            <meta class="swiftype" name="image" data-type="enum" content="https://example.com/orignal.jpg"/>
        
    
    <!--STYLES-->
    
<link rel="stylesheet" href="/assets/css/style-xvfnj2o9xv19zzpzzydweqhvegynmqvndecmgp9x1tqnkjmbbtwsdcdaxggz.min.css">

    <!--STYLES END-->
    

    

    
</head>

    <body>
        <div id="blog">
            <!-- Define author's picture -->


    

<header id="header" data-behavior="4">
    <i id="btn-open-sidebar" class="fa fa-lg fa-bars"></i>
    <div class="header-title">
        <a
            class="header-title-link"
            href="/"
            aria-label=""
        >
            Hexo
        </a>
    </div>
    
        
            <a
                class="header-right-picture "
                href="#about"
                aria-label="打开链接: /#about"
            >
        
        
        </a>
    
</header>

            <!-- Define author's picture -->


<nav id="sidebar" data-behavior="4">
    <div class="sidebar-container">
        
        
            <ul class="sidebar-buttons">
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="/"
                            
                            rel="noopener"
                            title="首页"
                        >
                        <i class="sidebar-button-icon fa fa-home" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">首页</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="/all-categories"
                            
                            rel="noopener"
                            title="分类"
                        >
                        <i class="sidebar-button-icon fa fa-bookmark" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">分类</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="/all-tags"
                            
                            rel="noopener"
                            title="标签"
                        >
                        <i class="sidebar-button-icon fa fa-tags" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">标签</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="/all-archives"
                            
                            rel="noopener"
                            title="归档"
                        >
                        <i class="sidebar-button-icon fa fa-archive" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">归档</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link open-algolia-search"
                            href="#search"
                            
                            rel="noopener"
                            title="搜索"
                        >
                        <i class="sidebar-button-icon fa fa-search" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">搜索</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="#about"
                            
                            rel="noopener"
                            title="关于"
                        >
                        <i class="sidebar-button-icon fa fa-question" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">关于</span>
                    </a>
            </li>
            
        </ul>
        
            <ul class="sidebar-buttons">
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="https://github.com/1416018124"
                            
                                target="_blank"
                            
                            rel="noopener"
                            title="GitHub"
                        >
                        <i class="sidebar-button-icon fab fa-github" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">GitHub</span>
                    </a>
            </li>
            
        </ul>
        
    </div>
</nav>

            
        <div class="post-header-cover
                    text-center
                    post-header-cover--full"
             style="background-image:url('/%E5%8D%95%E8%8A%82%E7%82%B9%E9%83%A8%E7%BD%B2ceph/image-2.png');"
             data-behavior="4">
            
        </div>

            <div id="main" data-behavior="4"
                 class="hasCover
                        hasCoverMetaOut
                        hasCoverCaption">
                
<article class="post">
    
        <span class="post-header-cover-caption caption">A beautiful sunrise</span>
    
    
        <div class="post-header main-content-wrap text-center">
    
        <h1 class="post-title">
            单节点部署ceph
        </h1>
    
    
</div>

    
    <div class="post-content markdown">
        <div class="main-content-wrap">
            <span id="more"></span>

<h1 id="1-机器规划"><a href="#1-机器规划" class="headerlink" title="1.机器规划"></a>1.机器规划</h1><table>
<thead>
<tr>
<th>hostname</th>
<th>ip</th>
<th>配置</th>
<th>os</th>
</tr>
</thead>
<tbody><tr>
<td>ceph</td>
<td>192.168.3.27</td>
<td>8c-32g</td>
<td>ubuntut 22.04.5lts</td>
</tr>
</tbody></table>
<h1 id="2-软件部署"><a href="#2-软件部署" class="headerlink" title="2.软件部署"></a>2.软件部署</h1><h2 id="2-1前置依赖"><a href="#2-1前置依赖" class="headerlink" title="2.1前置依赖"></a>2.1前置依赖</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">apt-get install apt-transport-https ca-certificates curl software-properties-common -y</span><br><span class="line">curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg</span><br><span class="line">echo &quot;deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu jammy stable&quot; | sudo tee /etc/apt/sources.list.d/docker.list &gt; /dev/null</span><br><span class="line"> apt-get update</span><br><span class="line"> apt-get install docker-ce docker-ce-cli containerd.io -y</span><br><span class="line"> apt-get install ntp lvm2 -y</span><br><span class="line"> tzselect</span><br><span class="line"> cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h2 id="2-2安装cephadm"><a href="#2-2安装cephadm" class="headerlink" title="2.2安装cephadm"></a>2.2安装cephadm</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">wget -q -O- ‘https://download.ceph.com/keys/release.asc’ | sudo apt-key add -</span><br><span class="line">apt-get install cephadm</span><br></pre></td></tr></table></figure>



<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br></pre></td><td class="code"><pre><span class="line">cephadm bootstrap --mon-ip 192.168.142.103</span><br><span class="line">Creating directory /etc/ceph for ceph.conf</span><br><span class="line">Verifying podman|docker is present...</span><br><span class="line">Verifying lvm2 is present...</span><br><span class="line">Verifying time synchronization is in place...</span><br><span class="line">Unit ntp.service is enabled and running</span><br><span class="line">Repeating the final host check...</span><br><span class="line">docker (/usr/bin/docker) is present</span><br><span class="line">systemctl is present</span><br><span class="line">lvcreate is present</span><br><span class="line">Unit ntp.service is enabled and running</span><br><span class="line">Host looks OK</span><br><span class="line">Cluster fsid: 0a772fca-c53c-11ef-ae86-ed4a98cf590a</span><br><span class="line">Verifying IP 192.168.3.27 port 3300 ...</span><br><span class="line">Verifying IP 192.168.3.27 port 6789 ...</span><br><span class="line">Mon IP `192.168.3.27` is in CIDR network `192.168.3.0/24`</span><br><span class="line">Mon IP `192.168.3.27` is in CIDR network `192.168.3.0/24`</span><br><span class="line">Mon IP `192.168.3.27` is in CIDR network `192.168.3.1/32`</span><br><span class="line">Mon IP `192.168.3.27` is in CIDR network `192.168.3.1/32`</span><br><span class="line">Internal network (--cluster-network) has not been provided, OSD replication will default to the public_network</span><br><span class="line">Pulling container image quay.io/ceph/ceph:v17...</span><br><span class="line">Ceph version: ceph version 17.2.8 (f817ceb7f187defb1d021d6328fa833eb8e943b3) quincy (stable)</span><br><span class="line">Extracting ceph user uid/gid from container image...</span><br><span class="line">Creating initial keys...</span><br><span class="line">Creating initial monmap...</span><br><span class="line">Creating mon...</span><br><span class="line">Waiting for mon to start...</span><br><span class="line">Waiting for mon...</span><br><span class="line">mon is available</span><br><span class="line">Assimilating anything we can from ceph.conf...</span><br><span class="line">Generating new minimal ceph.conf...</span><br><span class="line">Restarting the monitor...</span><br><span class="line">Setting mon public_network to 192.168.3.1/32,192.168.3.0/24</span><br><span class="line">Wrote config to /etc/ceph/ceph.conf</span><br><span class="line">Wrote keyring to /etc/ceph/ceph.client.admin.keyring</span><br><span class="line">Creating mgr...</span><br><span class="line">Verifying port 9283 ...</span><br><span class="line">Waiting for mgr to start...</span><br><span class="line">Waiting for mgr...</span><br><span class="line">mgr not available, waiting (1/15)...</span><br><span class="line">mgr not available, waiting (2/15)...</span><br><span class="line">mgr not available, waiting (3/15)...</span><br><span class="line">mgr is available</span><br><span class="line">Enabling cephadm module...</span><br><span class="line">Waiting for the mgr to restart...</span><br><span class="line">Waiting for mgr epoch 5...</span><br><span class="line">mgr epoch 5 is available</span><br><span class="line">Setting orchestrator backend to cephadm...</span><br><span class="line">Generating ssh key...</span><br><span class="line">Wrote public SSH key to /etc/ceph/ceph.pub</span><br><span class="line">Adding key to root@localhost authorized_keys...</span><br><span class="line">Adding host ceph...</span><br><span class="line">Deploying mon service with default placement...</span><br><span class="line">Deploying mgr service with default placement...</span><br><span class="line">Deploying crash service with default placement...</span><br><span class="line">Deploying prometheus service with default placement...</span><br><span class="line">Deploying grafana service with default placement...</span><br><span class="line">Deploying node-exporter service with default placement...</span><br><span class="line">Deploying alertmanager service with default placement...</span><br><span class="line">Enabling the dashboard module...</span><br><span class="line">Waiting for the mgr to restart...</span><br><span class="line">Waiting for mgr epoch 9...</span><br><span class="line">mgr epoch 9 is available</span><br><span class="line">Generating a dashboard self-signed certificate...</span><br><span class="line">Creating initial admin user...</span><br><span class="line">Fetching dashboard port number...</span><br><span class="line">Ceph Dashboard is now available at:</span><br><span class="line"></span><br><span class="line">	     URL: https://ceph:8443/</span><br><span class="line">	    User: admin</span><br><span class="line">	Password: lvoxog77g8</span><br><span class="line"></span><br><span class="line">Enabling client.admin keyring and conf on hosts with &quot;admin&quot; label</span><br><span class="line">Saving cluster configuration to /var/lib/ceph/0a772fca-c53c-11ef-ae86-ed4a98cf590a/config directory</span><br><span class="line">Enabling autotune for osd_memory_target</span><br><span class="line">You can access the Ceph CLI as following in case of multi-cluster or non-default config:</span><br><span class="line"></span><br><span class="line">	sudo /usr/sbin/cephadm shell --fsid 0a772fca-c53c-11ef-ae86-ed4a98cf590a -c /etc/ceph/ceph.conf -k /etc/ceph/ceph.client.admin.keyring</span><br><span class="line"></span><br><span class="line">Or, if you are only running a single cluster on this host:</span><br><span class="line"></span><br><span class="line">	sudo /usr/sbin/cephadm shell</span><br><span class="line"></span><br><span class="line">Please consider enabling telemetry to help improve Ceph:</span><br><span class="line"></span><br><span class="line">	ceph telemetry on</span><br><span class="line"></span><br><span class="line">For more information see:</span><br><span class="line"></span><br><span class="line">	https://docs.ceph.com/docs/master/mgr/telemetry/</span><br><span class="line"></span><br><span class="line">Bootstrap complete.</span><br></pre></td></tr></table></figure>

<p>此时根据上面的url可以登录到dashboard上.</p>
<h3 id="安装ceph-common"><a href="#安装ceph-common" class="headerlink" title="安装ceph-common"></a>安装<a target="_blank" rel="noopener" href="https://so.csdn.net/so/search?q=ceph&spm=1001.2101.3001.7020">ceph</a>-common</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">cephadm add-repo --release pacific</span><br><span class="line">ceph status</span><br><span class="line">  cluster:</span><br><span class="line">    id:     0a772fca-c53c-11ef-ae86-ed4a98cf590a</span><br><span class="line">    health: HEALTH_WARN</span><br><span class="line">            OSD count 0 &lt; osd_pool_default_size 3</span><br><span class="line"></span><br><span class="line">  services:</span><br><span class="line">    mon: 1 daemons, quorum ceph (age 16m)</span><br><span class="line">    mgr: ceph.cehgev(active, since 14m)</span><br><span class="line">    osd: 0 osds: 0 up, 0 in</span><br><span class="line"></span><br><span class="line">  data:</span><br><span class="line">    pools:   0 pools, 0 pgs</span><br><span class="line">    objects: 0 objects, 0 B</span><br><span class="line">    usage:   0 B used, 0 B / 0 B avail</span><br><span class="line">    pgs:</span><br></pre></td></tr></table></figure>



<h1 id="3-添加存储"><a href="#3-添加存储" class="headerlink" title="3.添加存储"></a>3.添加存储</h1><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph orch apply osd --all-available-devices</span><br></pre></td></tr></table></figure>



<h1 id="4-创建pool"><a href="#4-创建pool" class="headerlink" title="4.创建pool"></a>4.创建pool</h1><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">修改crush map</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">原因： 不然pool的创建会出问题，集群状态一直是不健康的，参考：Setting up a single node Ceph storage cluster</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">步骤：</span></span><br><span class="line">ceph status # Shows the status of the cluster</span><br><span class="line">ceph osd crush rule dump # Shows you the current crush maps</span><br><span class="line">ceph osd getcrushmap -o comp_crush_map.cm # Get crush map</span><br><span class="line">crushtool -d comp_crush_map.cm -o crush_map.cm # Decompile map</span><br><span class="line">vim crush_map.cm # Make and changes you need (host -&gt; osd)</span><br><span class="line">step chooseleaf firstn 0 type host 改为 step chooseleaf firstn 0 type osd,参考 如何在单节点 Ceph 中配置多数据副本</span><br><span class="line">crushtool -c crush_map.cm -o new_crush_map.cm # Compile map</span><br><span class="line">ceph osd setcrushmap -i new_crush_map.cm # Load the new map</span><br></pre></td></tr></table></figure>



<h1 id="5-配置一个s3存储"><a href="#5-配置一个s3存储" class="headerlink" title="5.配置一个s3存储"></a>5.配置一个s3存储</h1><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ceph orch apply rgw myrgw --placement=<span class="string">&quot;count:1&quot;</span></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ceph orch <span class="built_in">ls</span></span></span><br><span class="line">NAME                       PORTS        RUNNING  REFRESHED  AGE  PLACEMENT</span><br><span class="line">alertmanager               ?:9093,9094      1/1  3m ago     38m  count:1</span><br><span class="line">crash                                       1/1  3m ago     38m  *</span><br><span class="line">grafana                    ?:3000           1/1  3m ago     38m  count:1</span><br><span class="line">mgr                                         1/2  3m ago     38m  count:2</span><br><span class="line">mon                                         1/5  3m ago     38m  count:5</span><br><span class="line">node-exporter              ?:9100           1/1  3m ago     38m  *</span><br><span class="line">osd.all-available-devices                     1  3m ago     19m  *</span><br><span class="line">prometheus                 ?:9095           1/1  3m ago     38m  count:1</span><br><span class="line">rgw.myrgw                  ?:80             1/1  3m ago     3m   count:1</span><br></pre></td></tr></table></figure>

<h2 id="5-1生成s3访问凭证"><a href="#5-1生成s3访问凭证" class="headerlink" title="5.1生成s3访问凭证"></a>5.1生成s3访问凭证</h2><p>使用 <code>radosgw-admin</code> 命令来创建用户并生成 S3 访问所需的凭证：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">radosgw-admin user create --uid=&quot;s3user&quot; --display-name=&quot;S3 User&quot;</span><br></pre></td></tr></table></figure>





<h1 id="6-k8s上集成ceph"><a href="#6-k8s上集成ceph" class="headerlink" title="6.k8s上集成ceph"></a>6.k8s上集成ceph</h1><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">安装 Ceph-CSI 插件</span></span><br><span class="line">helm repo add ceph-csi https://ceph.github.io/csi-charts</span><br><span class="line">helm repo update</span><br><span class="line">kubectl create namespace ceph-cs</span><br><span class="line">helm install ceph-csi-cephfs ceph-csi/ceph-csi-cephfs --namespace ceph-csi</span><br><span class="line">helm install ceph-csi-rbd ceph-csi/ceph-csi-rbd --namespace ceph-csi</span><br></pre></td></tr></table></figure>

<h2 id="6-1创建-Ceph-存储类"><a href="#6-1创建-Ceph-存储类" class="headerlink" title="6.1创建 Ceph 存储类"></a>6.1创建 Ceph 存储类</h2><p>你需要创建存储类（Storage Class）以便 Kubernetes 可以使用 Ceph 存储。</p>
<p><strong>对于 CephFS 存储类</strong>：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">storage.k8s.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">StorageClass</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">cephfs-sc</span></span><br><span class="line"><span class="attr">provisioner:</span> <span class="string">cephfs.csi.ceph.com</span></span><br><span class="line"><span class="attr">parameters:</span></span><br><span class="line">  <span class="comment"># Ceph 集群的监视器地址</span></span><br><span class="line">  <span class="attr">monitors:</span> <span class="string">&lt;ceph_monitor_ips&gt;</span></span><br><span class="line">  <span class="comment"># Ceph 集群的池名称</span></span><br><span class="line">  <span class="attr">pool:</span> <span class="string">&lt;cephfs_pool_name&gt;</span></span><br><span class="line">  <span class="comment"># Ceph 集群的 CephFS 名称</span></span><br><span class="line">  <span class="attr">clusterID:</span> <span class="string">&lt;ceph_cluster_id&gt;</span></span><br><span class="line">  <span class="comment"># Ceph 用户名称</span></span><br><span class="line">  <span class="attr">csi.storage.k8s.io/provisioner-secret-name:</span> <span class="string">csi-cephfs-secret</span></span><br><span class="line">  <span class="attr">csi.storage.k8s.io/provisioner-secret-namespace:</span> <span class="string">ceph-csi</span></span><br><span class="line">  <span class="attr">csi.storage.k8s.io/node-stage-secret-name:</span> <span class="string">csi-cephfs-secret</span></span><br><span class="line">  <span class="attr">csi.storage.k8s.io/node-stage-secret-namespace:</span> <span class="string">ceph-csi</span></span><br><span class="line">  <span class="comment"># CephFS 根目录</span></span><br><span class="line">  <span class="attr">rootPath:</span> <span class="string">/</span></span><br><span class="line"><span class="attr">reclaimPolicy:</span> <span class="string">Delete</span></span><br><span class="line"><span class="attr">volumeBindingMode:</span> <span class="string">Immediate</span></span><br></pre></td></tr></table></figure>



<p><strong>对于 RBD 存储类</strong>：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">storage.k8s.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">StorageClass</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">rbd-sc</span></span><br><span class="line"><span class="attr">provisioner:</span> <span class="string">rbd.csi.ceph.com</span></span><br><span class="line"><span class="attr">parameters:</span></span><br><span class="line">  <span class="comment"># Ceph 集群的监视器地址</span></span><br><span class="line">  <span class="attr">monitors:</span> <span class="string">&lt;ceph_monitor_ips&gt;</span></span><br><span class="line">  <span class="comment"># Ceph 集群的池名称</span></span><br><span class="line">  <span class="attr">pool:</span> <span class="string">&lt;rbd_pool_name&gt;</span></span><br><span class="line">  <span class="comment"># Ceph 用户名称</span></span><br><span class="line">  <span class="attr">csi.storage.k8s.io/provisioner-secret-name:</span> <span class="string">csi-rbd-secret</span></span><br><span class="line">  <span class="attr">csi.storage.k8s.io/provisioner-secret-namespace:</span> <span class="string">ceph-csi</span></span><br><span class="line">  <span class="attr">csi.storage.k8s.io/node-stage-secret-name:</span> <span class="string">csi-rbd-secret</span></span><br><span class="line">  <span class="attr">csi.storage.k8s.io/node-stage-secret-namespace:</span> <span class="string">ceph-csi</span></span><br><span class="line">  <span class="comment"># RBD 映像格式</span></span><br><span class="line">  <span class="attr">imageFormat:</span> <span class="string">&quot;2&quot;</span></span><br><span class="line">  <span class="comment"># RBD 映像特性</span></span><br><span class="line">  <span class="attr">imageFeatures:</span> <span class="string">&quot;layering&quot;</span></span><br><span class="line"><span class="attr">reclaimPolicy:</span> <span class="string">Delete</span></span><br><span class="line"><span class="attr">volumeBindingMode:</span> <span class="string">Immediate</span></span><br></pre></td></tr></table></figure>

<p>将上述 YAML 文件保存为 <code>cephfs-sc.yaml</code> 或 <code>rbd-sc.yaml</code>，并使用以下命令创建存储类：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kubectl create -f cephfs-sc.yaml</span><br><span class="line">kubectl create -f rbd-sc.yaml</span><br></pre></td></tr></table></figure>

            

    
    <div class="image-gallery">
        <div class="image-gallery-metabar">
            <span>画廊: 4 图片</span>
        </div>
        <div class="image-gallery-photos image-gallery-photos--thumbnail">
            
            
            <div class="photo-box">
                <a
                    class="photo-box-inner fancybox"
                    data-fancybox="gallery-cm860r0zx000ou266bbk41b4i"
                    data-caption="New York"
                    title="New York"
                    href="https://1416018124.github.io/%E5%8D%95%E8%8A%82%E7%82%B9%E9%83%A8%E7%BD%B2ceph/image-3.jpg"
                    aria-label=""
                >
                    

                        <img
                                class="photo" src="https://1416018124.github.io/%E5%8D%95%E8%8A%82%E7%82%B9%E9%83%A8%E7%BD%B2ceph/image-3.jpg"
                        >
                    
                </a>
            </div>
            
            
            <div class="photo-box">
                <a
                    class="photo-box-inner fancybox"
                    data-fancybox="gallery-cm860r0zx000ou266bbk41b4i"
                    data-caption="Paris"
                    title="Paris"
                    href="https://1416018124.github.io/%E5%8D%95%E8%8A%82%E7%82%B9%E9%83%A8%E7%BD%B2ceph/image-4.png"
                    aria-label=""
                >
                    

                        <img
                                class="photo" src="https://1416018124.github.io/%E5%8D%95%E8%8A%82%E7%82%B9%E9%83%A8%E7%BD%B2ceph/image-4.png"
                        >
                    
                </a>
            </div>
            
            
            <div class="photo-box">
                <a
                    class="photo-box-inner fancybox"
                    data-fancybox="gallery-cm860r0zx000ou266bbk41b4i"
                    data-caption="Dubai"
                    title="Dubai"
                    target="_blank" rel="noopener" href="http://i.imgur.com/o9r19kD.jpg"
                    aria-label=""
                >
                    

                        <img
                                class="photo" src="http://i.imgur.com/o9r19kD.jpg"
                        >
                    
                </a>
            </div>
            
            
            <div class="photo-box">
                <a
                    class="photo-box-inner fancybox"
                    data-fancybox="gallery-cm860r0zx000ou266bbk41b4i"
                    data-caption="Sidney"
                    title="Sidney"
                    target="_blank" rel="noopener" href="https://example.com/orignal.jpg"
                    aria-label=""
                >
                    
                </a>
            </div>
            
        </div>
    </div>


        </div>
    </div>
    <div id="post-footer" class="post-footer main-content-wrap">
        
            <div class="post-footer-tags">
                <span class="text-color-light text-small">标签</span><br/>
                
    <a class="tag tag--primary tag--small t-none-link" href="/tags/k8s/" rel="tag">k8s</a> <a class="tag tag--primary tag--small t-none-link" href="/tags/%E8%BF%90%E7%BB%B4/" rel="tag">运维</a>

            </div>
        
        
        
    </div>
</article>



                <footer id="footer" class="main-content-wrap">
    <span class="copyrights">
        Copyrights &copy; 2025 Jiang Feng. All Rights Reserved.
    </span>
</footer>

            </div>
            
        </div>
        


<div id="about">
    <div id="about-card">
        <div id="about-btn-close">
            <i class="fa fa-times"></i>
        </div>
        
            <h4 id="about-card-name">Jiang Feng</h4>
        
            <div id="about-card-bio"><p>author.bio</p>
</div>
        
        
            <div id="about-card-job">
                <i class="fa fa-briefcase"></i>
                <br/>
                <p>author.job</p>

            </div>
        
        
    </div>
</div>

        
        
<div id="cover" style="background-image:url('/assets/images/cover.jpg');"></div>
        <!--SCRIPTS-->

<script src="/assets/js/script-p2ssgnbftin4xedccxbuog4edl9jkt5x6ei7phvwevjlrkkr0xvvl08iwpyl.min.js"></script>

<!--SCRIPTS END-->





    </body>
</html>
